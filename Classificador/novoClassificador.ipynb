{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Treinamento de classificador** para realização de análise de sentimentos (modelo baseado em atividade da disciplina de PLN - PUCPR).\n",
        "Iremos desenvolver o classificador, utilizando uma abordagem supervisionada, ou seja, precisaremos de dados rotulados com suas respectivas emoções."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltdhOVMyY9PW"
      },
      "source": [
        "#### Fluxo de execução\n",
        "Vamos seguir o seguinte fluxo de processamento dos dados:\n",
        "\n",
        "\n",
        "1.   Abrir o corpus\n",
        "2.   Remover as stop-words\n",
        "3.   Aplicar stemmer\n",
        "4.   Gerar o Bag of Words\n",
        "5.   Treinar o modelo SVM\n",
        "6.   Predizer/Avaliar o modelo\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5j_ZSI5Ccrs"
      },
      "source": [
        "**1) Primeira parte** - Nesse início de execução do algoritmo, foi realizado a **Redução da granularidade dos sentimentos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtuY_lI4SufL"
      },
      "outputs": [],
      "source": [
        "# Abre corpus para leitura\n",
        "f = open(\"analise-sentimentos-2000-noticias.txt\", \"r\", encoding=\"utf-8-sig\")\n",
        "\n",
        "#Variável que recebe todas as linhas do doc aberto anteriormente\n",
        "linhas = f.readlines()\n",
        "\n",
        "#Variável criada para receber as linhas sem o rótulo 'surpresa'\n",
        "#Foi realizada uma iteração linha por linha para verificação\n",
        "nova_lista = [item for item in linhas if not item.startswith(\"surpresa\")]\n",
        "\n",
        "#Variáveis que receberão a separação de rótulos e textos\n",
        "corpus_textos = []\n",
        "corpus_rotulos = []\n",
        "\n",
        "# Percorre as linhas\n",
        "for linha in nova_lista:\n",
        "\n",
        "  # Separa texto e rótulo/categoria/emoção\n",
        "  item = linha.split(\";;\")\n",
        "\n",
        "  #adiciona às variáveis especificadas os rótulos e textos de cada linha\n",
        "  corpus_rotulos.append(item[0])\n",
        "  corpus_textos.append(item[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwJXwrDFmCZJ",
        "outputId": "96939454-84e3-4286-91bf-8c00a246e45f"
      },
      "outputs": [],
      "source": [
        "#Nova lista criada sem as linhas do rótulo 'surpresa'\n",
        "print(nova_lista)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeR6Rr1wV1oG",
        "outputId": "f1f803be-bebd-4e44-bc8a-bcc3c8d9c1e8"
      },
      "outputs": [],
      "source": [
        "# 5 primeiros textos\n",
        "corpus_textos[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QZi8RdDmqGG",
        "outputId": "24eba6f9-19d2-44d4-aa9c-ab770d39b84b"
      },
      "outputs": [],
      "source": [
        "#Novo tamanho de texto sem os textos que tinham como rótulo 'surpresa'\n",
        "len(corpus_textos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ceMmKwGUtvR",
        "outputId": "dbe44fa3-a17a-4c3b-feea-04d30979fbe3"
      },
      "outputs": [],
      "source": [
        "#Variável que contém os novos rótulos (positivo, negativo e neutro)\n",
        "novos_rotulos = {\"alegria\":\"positivo\", \"raiva\":\"negativo\", \"medo\":\"negativo\", \"desgosto\":\"negativo\", \"tristeza\":\"negativo\", \"neutro\":\"neutro\"}\n",
        "\n",
        "# Lista com os rótulos antigos\n",
        "rotulos_antigos = corpus_rotulos\n",
        "\n",
        "# Lista com os rótulos atualizados\n",
        "rotulos_atualizados = [novos_rotulos[rotulo] for rotulo in rotulos_antigos]\n",
        "\n",
        "#Exibe os novos rótulos\n",
        "print(rotulos_atualizados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFK1WX7ZahKc",
        "outputId": "03f990a5-b950-4925-b77a-1bb937111605"
      },
      "outputs": [],
      "source": [
        "rotulos_atualizados[0:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyGfOawHbrIu",
        "outputId": "79082a9e-be51-4c4e-840a-921fce0e98f2"
      },
      "outputs": [],
      "source": [
        "#Tamanho atualizado dos rótulos (mesmo tamanho dos textos)\n",
        "len(rotulos_atualizados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1_UDTTha58a",
        "outputId": "f29164e9-b724-4550-dd33-52ea18e629cf"
      },
      "outputs": [],
      "source": [
        "corpus_rotulos[0:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhazTW3-bvWW",
        "outputId": "c17a4c5d-7a11-407a-bd03-9d875bd2c07a"
      },
      "outputs": [],
      "source": [
        "#Corpus com rótulos antigos usado para mostrar a atualização,\n",
        "#ou seja, a retirada dos textos com rótulos de 'surpresa'\n",
        "len(corpus_rotulos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMh3t4S-k5iN"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# O próprio sklearn tem um método para dividir a base de dados em treinamento e teste\n",
        "# Neste caso estamos deixando 90% para treinamento e 10% para testes\n",
        "corpus_treinamento, corpus_teste, rotulos_treinamento, rotulos_teste = train_test_split(corpus_textos, rotulos_atualizados, test_size=0.10, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlOXBwE9l1DQ",
        "outputId": "57d70026-ef01-4b12-fd2c-e4334f93741b"
      },
      "outputs": [],
      "source": [
        "#Tamanho do corpus de treinamento\n",
        "len(corpus_treinamento)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNkXDsCzl3CK",
        "outputId": "10d53917-4923-449b-9fea-0c8f9e1fdf6b"
      },
      "outputs": [],
      "source": [
        "#Tamanho do corpus de teste\n",
        "len(corpus_teste)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k8IhkJhl3F8",
        "outputId": "69a915d1-0ac1-4f7c-e666-2d0d795ea75f"
      },
      "outputs": [],
      "source": [
        "#Tamanho dos rótulos de treinamento\n",
        "len(rotulos_treinamento)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5jSA7_Ql3Jo",
        "outputId": "74613fb0-c254-46dc-ceb6-e06bb22fa66e"
      },
      "outputs": [],
      "source": [
        "#Tamanho dos rótulos de teste\n",
        "len(rotulos_teste)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbSXzp5fvFk3"
      },
      "source": [
        "Vamos deixar preparada uma função para pré-processar os textos, utilizando uma lista de stop-words com novos itens, o stemming e normalização dos textos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5CAMkykvRUk",
        "outputId": "c0af5a62-ec07-46e8-d63f-134707ca603c"
      },
      "outputs": [],
      "source": [
        "#Importação das bibliotecas usadas para pré-processamento de texto\n",
        "import nltk\n",
        "from nltk import tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('rslp')\n",
        "nltk.download('punkt')\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('portuguese') #carrega stopwords da lingua portuguesa disponíveis no NLTK\n",
        "stopwords += (',','.','(',')','\"',\"'\",'´','`','!','$','%','&','...','-',':',';','?','``','\\'\\'') #acrescenta simbolos\n",
        "stopwords += ('a','e','i','o','u','A','E','I','O','U') #acrescenta também vogais\n",
        "\n",
        "stemmer = nltk.stem.RSLPStemmer()\n",
        "\n",
        "#Função de pré-processamento de texto (lowercase, tokenização, stopwords e stemmização)\n",
        "def my_preprocessor(text):\n",
        "\n",
        "    # Normaliza para minúsculas\n",
        "    text=text.lower()\n",
        "\n",
        "    # Tokeniza\n",
        "    words = tokenize.word_tokenize(text, language='portuguese')\n",
        "    # Remove stop-words\n",
        "    words_no_stopwords = [word for word in words if not word in stopwords]\n",
        "    # Aplica stemming\n",
        "    stemmed_words=[stemmer.stem(word=word) for word in words_no_stopwords]\n",
        "    return ' '.join(stemmed_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HnBLMGtmxNm"
      },
      "source": [
        "2) **Segunda parte** - **Configuração dos parâmetros de extração de atributos e do classificador**. Aqui foram alterados os parâmetros, tanto do CountVectorizer quanto do classificador (SVC) e foram encotrados algumas diferenças na acurácia do treinamento e teste. Deixarei os exeplos escritos abaixo e comentados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20ZDBuVTmxbU"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Primeiro aplica o BoW, depois envia dados ao classificador SVM\n",
        "# (SEM retirada de stop-words e stemming)\n",
        "#Testar cada linha com diferenças entre parâmetros\n",
        "\n",
        "#Aqui, optei por inserir o parâmetro 'max_df' no CountVectorizer e manter o SVC como estava\n",
        "sent_clf = Pipeline([('vect', CountVectorizer(max_df=0.50)),('clf', SVC(kernel='linear', C=1))])\n",
        "\n",
        "#Nessa linha, optei por alterar o parâmetro 'C' do SVC para 2, houve pouca mudança na acurária em relação a linha de cima\n",
        "#sent_clf = Pipeline([('vect', CountVectorizer()),('clf', SVC(kernel='linear', C=2))])\n",
        "\n",
        "#Nessa linha, optei por alterar tanto o 'vect (max_df), quanto o parâmetro 'C' do SVC, houve um aumento da acurária em relação a linha de cima\n",
        "#sent_clf = Pipeline([('vect', CountVectorizer(max_df=0.50)),('clf', SVC(kernel='linear', C=2))])\n",
        "\n",
        "# (COM retirada de stop-words e stemming)\n",
        "#sent_clf = Pipeline([('vect', CountVectorizer(preprocessor = my_preprocessor)),('clf', SVC(kernel='linear', C=1))])\n",
        "\n",
        "#Aqui optei por adicionar ao vectorizer o ngram_range e alterar o parâmetro 'C' do SVC.\n",
        "#Houve uma diminuição considerável na acurácia se comparado com as outras linhas acima\n",
        "#sent_clf = Pipeline([('vect', CountVectorizer(preprocessor = my_preprocessor, ngram_range=(2,2))),('clf', SVC(kernel='linear', C=2))])\n",
        "\n",
        "#Nesta linha, optei por alterar somento o parâmetro 'ngram_range' e houve melhora na acurácia em relação a linha de cima\n",
        "#sent_clf = Pipeline([('vect', CountVectorizer(preprocessor = my_preprocessor, ngram_range=(1,1))),('clf', SVC(kernel='linear', C=1))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7MxOYY4SzNu"
      },
      "source": [
        "3) **Terceira parte** - **Novas etapas de extração de atributos ou de pré-processamento**. Nesta etapa optei por importar o TfidfTransformer para transformar a matriz gerada pelo Vectorizer em em uma representação TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSn-mFpUOoru"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "#Adição do TF-IDF ao pipeline para transformação da matriz\n",
        "#Optei por deixar comentado a linha abaixo para testar outro classificador\n",
        "#sent_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', SVC(kernel='linear', C=1))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pdy57HUKWHmf"
      },
      "source": [
        "4) **Quarta parte - Utilização de outro classificador de texto**. Aqui, optei por trocar SVC pelo MultinomialNB para classificar o texto. Houve diferenças na acurácia dos treinamento e testes realizados em comparação aos métodos testados acima."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kh418yFSVebm"
      },
      "outputs": [],
      "source": [
        "#importação do classificador de Naive Bayes\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "#Substituição do classificador SVC pelo MultinomialNB\n",
        "sent_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', MultinomialNB())])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcUiVr1exebT"
      },
      "outputs": [],
      "source": [
        "# Inicia treinamento\n",
        "sent_clf = sent_clf.fit(corpus_treinamento, rotulos_treinamento)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ6nzypDoHTX"
      },
      "source": [
        "Já temos nosso modelo treinado! Agora vamos predizer a base de teste e avaliar os resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNSFAIiYoHdD"
      },
      "outputs": [],
      "source": [
        "# Prediz base de teste\n",
        "rotulos_preditos = sent_clf.predict(corpus_teste)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FxFWGaBoZ_w",
        "outputId": "61f87658-fd36-422c-9a2f-2956f3ba7a9a"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Mostra relatório completo de avaliação\n",
        "print(classification_report(rotulos_teste, rotulos_preditos))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "qRQDI8b9oaFe",
        "outputId": "fdf4cab7-7d79-4875-e9bb-8ef7d44dc647"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Podemos imprimir a matriz de confusão para tentar entender melhor os resultados\n",
        "mat = confusion_matrix(rotulos_teste, rotulos_preditos)\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "\n",
        "rotulos_nomes = [\"negativo\", \"positivo\", \"neutro\"]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5,5))\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False, xticklabels=rotulos_nomes, yticklabels=rotulos_nomes )\n",
        "plt.xlabel('Categoria verdadeira')\n",
        "plt.ylabel('Categoria predita');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOHSe5TSW2Qt"
      },
      "source": [
        "**CONCLUSÃO** - Foi particularmente difícil realizar a primeira etapa, a da redução de granulidade, enquanto que as outras etapas foram mais tranquilas. Percebe-se a diferença de resultados de acurácia quando combinados diferentes parâmetros, classificadores e etapas de extração de atributos."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
